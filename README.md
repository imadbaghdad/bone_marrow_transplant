
# **Projet de Transplantation de Moelle Osseuse**
## **Explication des √©tapes suivies dans le notebook "eda.ipynb"**
L'objectif du notebook est d'explorer et de pr√©traiter un dataset contenant des informations sur les greffes de moelle osseuse. L'analyse comprend les √©tapes suivantes :

**Chargement du dataset**

**V√©rification et visualisation des valeurs manquantes**

**Gestion des valeurs manquantes**

**Premi√®re tentative : Remplacement g√©n√©ral par la moyenne (√©chec)**

**Seconde tentative : Remplacement des valeurs manquantes uniquement pour les colonnes num√©riques (succ√®s)**

**Nettoyage approfondi des valeurs manquantes**

**Stockage des donn√©es nettoy√©es**

**Winsorization (traitement des valeurs extr√™mes)**




### **1. Chargement du Dataset**

import pandas as pd
from scipy.io import arff

**Load the ARFF file**

data, meta = arff.loadarff("../data/bone-marrow.arff")

**Convert to a pandas DataFrame**

df = pd.DataFrame(data)

**Display the first few rows of the DataFrame**

df.head()

**Explication :**

Le fichier .arff est charg√© avec arff.loadarff().
Les donn√©es sont converties en DataFrame Pandas pour √™tre manipulables.
df.head() affiche les 5 premi√®res lignes du dataset.

**R√©sultat attendu :** 

Un aper√ßu du dataset sous forme tabulaire.

### **2. V√©rification des Valeurs Manquantes**

**Check for missing values**

missing_values = df.isnull().sum()
print("Missing values in each column:")
print(missing_values)

**Explication :**

df.isnull().sum() comptabilise les valeurs NaN dans chaque colonne.
Le r√©sultat affiche le nombre de valeurs manquantes par colonne.

**R√©sultat attendu :**

Un aper√ßu des premi√®res lignes avec les diff√©rentes variables et leurs valeurs, ce qui aide √† identifier le format et √©ventuellement les types de donn√©es.

### **3. Analyse des valeurs manquantes**

Pour comprendre la qualit√© des donn√©es, on proc√®de √† un contr√¥le des valeurs manquantes dans chaque colonne.

**Check for missing values**

missing_values = df.isnull().sum()
print("Missing values in each column:")
print(missing_values)

**Explications :**

df.isnull() cr√©e un DataFrame de bool√©ens indiquant o√π se trouvent les valeurs manquantes.
La m√©thode sum() appliqu√©e sur ce DataFrame agr√®ge le nombre de valeurs manquantes pour chaque colonne.
L‚Äôaffichage permet de voir quelles colonnes contiennent des NaN ou valeurs absentes.

**R√©sultat attendu :**

Un compte d√©taill√© des valeurs manquantes par colonne, ce qui permet de d√©cider comment traiter ces donn√©es manquantes.

### **4. Visualisation graphique des valeurs manquantes**

Pour une meilleure compr√©hension visuelle, on utilise une carte thermique (heatmap) pour repr√©senter la pr√©sence de valeurs manquantes dans le dataset.
import seaborn as sns
import matplotlib.pyplot as plt

**Visualize missing values**

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

**Explications :**

Seaborn et Matplotlib permettent de g√©n√©rer des graphiques de haute qualit√©.
La heatmap est construite √† partir de df.isnull(), o√π chaque cellule indique (par une couleur) si une valeur est manquante ou non.
L‚Äôutilisation de la palette de couleurs viridis offre un contraste permettant d‚Äôidentifier facilement les zones probl√©matiques.

**R√©sultat attendu :**

Un graphique o√π les zones avec des valeurs manquantes se distinguent visuellement, facilitant l‚Äôidentification de colonnes n√©cessitant un traitement particulier.

### **5. Traitement des valeurs manquantes**

On traite ensuite les valeurs manquantes en les rempla√ßant par la moyenne des valeurs de chaque colonne.

**Fill missing values with the mean of each column**

df.fillna(df.mean(), inplace=True)

**Explications :**

df.fillna(df.mean(), inplace=True) : Cette instruction calcule la moyenne de chaque colonne num√©rique et remplace directement les NaN par ces moyennes.
L‚Äôargument inplace=True permet d‚Äôappliquer le changement directement sur le DataFrame sans devoir cr√©er une nouvelle variable.

**R√©sultat attendu :**

Le DataFrame df ne comporte plus de valeurs manquantes dans les colonnes num√©riques, ce qui est essentiel pour de nombreuses m√©thodes d‚Äôanalyse et algorithmes de machine learning.

### **6. V√©rification post-traitement**

Pour confirmer que le traitement des valeurs manquantes a bien √©t√© effectu√©, on g√©n√®re une nouvelle heatmap.

**Verify that there are no more missing values**

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap After Handling')
plt.show()

**Explications :**

La deuxi√®me heatmap permet de v√©rifier visuellement que toutes les cases initialement identifi√©es comme manquantes ont bien √©t√© remplies.
L‚Äôabsence de couleurs indiquant des valeurs manquantes confirme la r√©ussite du traitement.

**R√©sultat attendu :**

Une heatmap compl√®tement "propre", c‚Äôest-√†-dire sans indication de valeurs manquantes, prouvant que toutes les anomalies ont √©t√© corrig√©es.

### **7. Nettoyage approfondi des valeurs manquantes**

**Fill missing values with the mean of each numeric column**

numeric_cols = df.select_dtypes(include=['number']).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

**Check for remaining missing values**

missing_values = df.isnull().sum()
print("Missing values in each column after handling:")
print(missing_values)

 **Explication :**

V√©rification plus pr√©cise des colonnes num√©riques.
Affichage des valeurs manquantes restantes.

**R√©sultat attendu :**

Un affichage indiquant si toutes les valeurs ont bien √©t√© corrig√©es.

### **8. Confirmation finale de la correction**

if missing_values.sum() == 0:
    print("There are no missing values left in the dataset.")
else:
    print("There are still missing values in the dataset.")

**Explication :**

V√©rifie s'il reste des valeurs manquantes apr√®s traitement.

**R√©sultat attendu :**

Un message confirmant que toutes les valeurs ont √©t√© corrig√©es.

### **9. Stockage des donn√©es nettoy√©es**

df_cleaned = df.copy()

 **Explication :**

Sauvegarde des donn√©es nettoy√©es pour des analyses ult√©rieures.

### **10. Visualisation des distributions avant transformation**

plt.figure(figsize=(15, 10))
df_cleaned[numeric_cols].boxplot()
plt.xticks(rotation=90)
plt.title('Box Plot for Numeric Columns Before Winsorization')
plt.show()

plt.figure(figsize=(15, 10))
df_cleaned[numeric_cols].hist(bins=30, layout=(len(numeric_cols) // 3 + 1, 3))
plt.suptitle('Histogram for Numeric Columns Before Winsorization', y=1.02)
plt.tight_layout()
plt.show()

**Explication :**

Visualisation des donn√©es avec des boxplots et des histogrammes.

**R√©sultat attendu :**

Des graphiques montrant la distribution des variables num√©riques.

### **11. Winsorization (traitement des valeurs extr√™mes)**

from scipy.stats.mstats import winsorize

df_winsorized = df_cleaned.copy()
for col in numeric_cols:
    df_winsorized[col] = winsorize(df_cleaned[col], limits=[0.05, 0.05])

**Explication :**

La Winsorization r√©duit l'impact des valeurs extr√™mes en limitant les valeurs extr√™mes √† 5% inf√©rieur et sup√©rieur.

**R√©sultat attendu :**

Un dataset o√π les outliers sont att√©nu√©s.

### **12. Visualisation apr√®s Winsorization**

plt.figure(figsize=(15, 10))
df_winsorized[numeric_cols].boxplot()
plt.xticks(rotation=90)
plt.title('Box Plot for Numeric Columns After Winsorization')
plt.show()

plt.figure(figsize=(15, 10))
df_winsorized[numeric_cols].hist(bins=30, layout=(len(numeric_cols) // 3 + 1, 3))
plt.suptitle('Histogram for Numeric Columns After Winsorization', y=1.02)
plt.tight_layout()
plt.show()

**Explication :**

Comparaison entre les distributions avant et apr√®s Winsorization.

**R√©sultat attendu :**

Des distributions moins influenc√©es par les valeurs extr√™mes.

### **13. Sauvegarde des donn√©es finales**

df_winsorized.to_csv('../data/winsorized_data.csv', index=False)
print("Winsorized data has been exported to '../data/winsorized_data.csv'")

**Explication :**

Sauvegarde du dataset nettoy√© et transform√©.

**R√©sultat attendu :**

Un fichier CSV contenant les donn√©es pr√™tes pour l'analyse ou le machine learning.



## **Explication des √©tapes suivies dans le notebook "eda2.ipynb"**

### **1. Importation des biblioth√®ques et chargement des donn√©es**

import pandas as pd
from scipy.io import arff

**Chargement du fichier ARFF**

data, meta = arff.loadarff("../data/bone-marrow.arff")

**Conversion en DataFrame Pandas**

df = pd.DataFrame(data)

**Affichage des premi√®res lignes**

df.head()

 **Explication**

pandas est import√© pour manipuler les donn√©es sous forme de tableau.
scipy.io.arff est utilis√© pour charger des fichiers .arff, format souvent utilis√© pour les datasets en machine learning.
arff.loadarff() charge les donn√©es et les m√©tadonn√©es.
df = pd.DataFrame(data) transforme les donn√©es en DataFrame.
df.head() affiche les 5 premi√®res lignes pour visualiser la structure des donn√©es.

**R√©sultat attendu**

Un aper√ßu du dataset avec ses premi√®res lignes et colonnes.

### **2. V√©rification des valeurs manquantes**

**V√©rification des valeurs manquantes**

missing_values = df.isnull().sum()
print("Valeurs manquantes par colonne:")
print(missing_values)

 **Explication**

df.isnull().sum() compte le nombre de valeurs NaN dans chaque colonne.

**R√©sultat attendu**

Une liste affichant les colonnes qui contiennent des valeurs manquantes et leur nombre.

### **3. Visualisation des valeurs manquantes**

import seaborn as sns
import matplotlib.pyplot as plt

**Heatmap des valeurs manquantes**

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Carte des valeurs manquantes')
plt.show()

**Explication**

sns.heatmap(df.isnull(), cbar=False, cmap='viridis') cr√©e une carte thermique pour rep√©rer les valeurs manquantes.

**R√©sultat attendu**

Un graphique o√π les cellules contenant des valeurs manquantes apparaissent en couleur.

### **4. Remplacement des valeurs manquantes**

**Remplissage avec la moyenne pour les colonnes num√©riques**

df.fillna(df.mean(), inplace=True)

**Explication**

df.fillna(df.mean(), inplace=True) remplace les valeurs NaN par la moyenne des colonnes.

**R√©sultat attendu**

Toutes les valeurs manquantes des colonnes num√©riques sont remplac√©es.

### **5. V√©rification apr√®s correction**

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Carte des valeurs manquantes apr√®s correction')
plt.show()

 **Explication**

Une nouvelle heatmap est affich√©e pour s‚Äôassurer qu‚Äôil ne reste plus de valeurs manquantes.

**R√©sultat attendu**

Une heatmap vide, confirmant l‚Äôabsence de valeurs manquantes.

### **6. Analyse des statistiques descriptives**

df.describe()

**Explication**

df.describe() g√©n√®re des statistiques (moyenne, m√©diane, √©cart-type, min, max) pour chaque variable num√©rique.

**R√©sultat attendu**

Un tableau avec des statistiques r√©sumant la distribution des donn√©es.

### **7. D√©tection des valeurs extr√™mes (outliers)**

plt.figure(figsize=(15, 10))
df.boxplot()
plt.xticks(rotation=90)
plt.title('Boxplot des colonnes num√©riques')
plt.show()

**Explication**

df.boxplot() affiche des boxplots pour chaque colonne afin de visualiser les valeurs extr√™mes.

**R√©sultat attendu**

Des points isol√©s en dehors des moustaches des boxplots indiquant la pr√©sence d'outliers.

### **8. Suppression des outliers**

from scipy.stats.mstats import winsorize

df_winsorized = df.copy()
for col in df.select_dtypes(include=['number']).columns:
    df_winsorized[col] = winsorize(df[col], limits=[0.05, 0.05])

**Explication**

Winsorization est appliqu√©e : les valeurs extr√™mes sont remplac√©es par des valeurs plus proches des percentiles 5% et 95%.

**R√©sultat attendu**

Un dataset avec des valeurs extr√™mes att√©nu√©es, sans modification excessive de la distribution.

### **9. V√©rification apr√®s Winsorization**

plt.figure(figsize=(15, 10))
df_winsorized.boxplot()
plt.xticks(rotation=90)
plt.title('Boxplot apr√®s Winsorization')
plt.show()

**Explication**

Affichage des nouveaux boxplots apr√®s r√©duction des outliers.

**R√©sultat attendu**

Moins de valeurs extr√™mes en dehors des moustaches des boxplots.

### **10. V√©rification de la distribution des variables**

df.hist(figsize=(12, 10), bins=30)
plt.suptitle('Histogrammes des variables')
plt.show()

**Explication**

df.hist() cr√©e des histogrammes pour voir la distribution de chaque variable.

**R√©sultat attendu**

Des graphiques montrant la forme des distributions (normale, asym√©trique, multimodale...).

### **11. Transformation des variables (normalisation)**

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df_winsorized), columns=df.columns)

**Explication**

Standardisation des donn√©es pour ramener toutes les variables √† une m√™me √©chelle (moyenne = 0, √©cart-type = 1).

**R√©sultat attendu**

Un dataset o√π toutes les variables sont transform√©es pour une meilleure comparabilit√©.

### **12. Sauvegarde des donn√©es nettoy√©es**

df_scaled.to_csv('../data/processed_data.csv', index=False)
print("Les donn√©es nettoy√©es ont √©t√© enregistr√©es.")

**Explication**

df_scaled.to_csv() enregistre le dataset nettoy√© et normalis√©.

**R√©sultat attendu**

Un fichier .csv pr√™t pour l'analyse ou l'entra√Ænement d'un mod√®le ML.

### **13. Analyse de la corr√©lation entre les variables**

plt.figure(figsize=(12, 8))
sns.heatmap(df_scaled.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Matrice de corr√©lation")
plt.show()

**Explication**

df_scaled.corr() calcule les coefficients de corr√©lation de Pearson entre les variables.
sns.heatmap() affiche une matrice de corr√©lation o√π les couleurs indiquent la force et la direction des relations.

**R√©sultat attendu**

Un heatmap montrant quelles variables sont fortement corr√©l√©es (+1 ou -1) et lesquelles sont ind√©pendantes (‚âà0).

### **14. R√©duction de dimension avec PCA**

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_scaled)

plt.scatter(df_pca[:, 0], df_pca[:, 1], alpha=0.5)
plt.xlabel("Composante principale 1")
plt.ylabel("Composante principale 2")
plt.title("Projection PCA des donn√©es")
plt.show()

**Explication**

PCA (Analyse en Composantes Principales) est utilis√© pour r√©duire la dimensionnalit√© tout en conservant le maximum de variance.
PCA(n_components=2) r√©duit les donn√©es √† 2 dimensions.
plt.scatter() visualise les donn√©es projet√©es sur ces deux axes principaux.

**R√©sultat attendu**

Un nuage de points repr√©sentant les donn√©es dans un espace √† 2 dimensions, facilitant l'interpr√©tation.

### **15. Clustering avec K-Means**

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=3, random_state=42)
df_scaled["Cluster"] = kmeans.fit_predict(df_scaled)

plt.scatter(df_pca[:, 0], df_pca[:, 1], c=df_scaled["Cluster"], cmap="viridis", alpha=0.5)
plt.xlabel("Composante principale 1")
plt.ylabel("Composante principale 2")
plt.title("Clustering K-Means sur les donn√©es PCA")
plt.show()

**Explication**

KMeans(n_clusters=3) applique un clustering en 3 groupes.
fit_predict(df_scaled) assigne un cluster √† chaque observation.
plt.scatter() colore les points selon leur cluster.

 **R√©sultat attendu**
 
Un nuage de points color√© o√π les observations sont regroup√©es en trois clusters.

### **16. √âvaluation du clustering avec l‚Äôinertie**

inertias = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df_scaled)
    inertias.append(kmeans.inertia_)

plt.plot(range(1, 11), inertias, marker="o")
plt.xlabel("Nombre de clusters")
plt.ylabel("Inertie")
plt.title("M√©thode du coude pour d√©terminer K")
plt.show()

**Explication**

On calcule l‚Äôinertie pour k entre 1 et 10.
L‚Äôinertie mesure la compacit√© des clusters.
La m√©thode du coude aide √† d√©terminer le nombre optimal de clusters.

**R√©sultat attendu**

Un graphique en forme de coude o√π l‚Äôinertie diminue rapidement avant de se stabiliser, indiquant le bon nombre de clusters.

### **17. Classification avec Random Forest**

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X = df_scaled.drop(columns=["Cluster"])
y = df_scaled["Cluster"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
print("Pr√©cision du mod√®le:", accuracy_score(y_test, y_pred))

**Explication**

Random Forest est utilis√© pour classifier les clusters obtenus.
train_test_split() s√©pare les donn√©es en 80% entra√Ænement / 20% test.
clf.fit(X_train, y_train) entra√Æne le mod√®le.
accuracy_score() mesure la pr√©cision de la classification.

**R√©sultat attendu**

Une pr√©cision indiquant dans quelle mesure le mod√®le distingue correctement les clusters.

### **18. Sauvegarde du mod√®le entra√Æn√©**

import joblib

joblib.dump(clf, "../models/random_forest_model.joblib")
print("Mod√®le sauvegard√©.")

**Explication**

joblib.dump() enregistre le mod√®le Random Forest pour une utilisation future.

**R√©sultat attendu**

Un fichier .joblib stockant le mod√®le entra√Æn√©.



## **Explication du code intitul√© "interface.py" qui permet de cr√©er notre interface**

### **1. Importation des biblioth√®ques**

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt

**Explication :**

streamlit : Permet de cr√©er une application web interactive.
pandas : Utilis√© pour manipuler les donn√©es tabulaires (format DataFrame).
numpy : Pour les op√©rations math√©matiques et manipulation des tableaux.
joblib : Sert √† charger le mod√®le de Machine Learning et l‚Äôexplainer SHAP.
shap : Utilis√© pour expliquer les d√©cisions du mod√®le (interpr√©tabilit√©).
matplotlib.pyplot : Permet de tracer des graphiques, notamment pour SHAP.

### **2. Chargement du mod√®le et de l‚Äôexplainer SHAP**

try:
    model = joblib.load(r'C:\Users\imadb\Documents\GitHub\bone_marrow_transplant\models\rf_model_compressed.joblib')
    explainer = joblib.load(r'C:\Users\imadb\Documents\GitHub\bone_marrow_transplant\models\shap_explainer_new.joblib')
except FileNotFoundError:
    st.error("Model files not found. Please ensure the model files are in the correct location.")
    st.stop()

**Explication :**

joblib.load() charge le mod√®le de Machine Learning (rf_model_compressed.joblib) et l‚Äôexplainer SHAP (shap_explainer_new.joblib).
Gestion d'erreur : Si les fichiers ne sont pas trouv√©s, un message d‚Äôerreur est affich√© avec st.error(), et st.stop() arr√™te l'ex√©cution de l'application.

### **3. Fonction de pr√©diction**

def predict_success_rate(data):
    df = pd.DataFrame([data])
    prediction = model.predict(df)
    prediction_proba = model.predict_proba(df)
    return prediction, prediction_proba

**Explication :**

Convertit les donn√©es d'entr√©e (data, un dictionnaire) en un DataFrame pandas.
Utilise model.predict() pour obtenir une pr√©diction (succ√®s ou √©chec de la greffe).
model.predict_proba() retourne les probabilit√©s de chaque classe (succ√®s ou √©chec).
Renvoie :
prediction : 0 ou 1 (succ√®s/√©chec).
prediction_proba : Probabilit√© associ√©e √† chaque classe.

### **4. Explication SHAP**

def generate_shap_explanation(data):
    try:
        df = pd.DataFrame([data])
        df = df[model.feature_names_in_]  
        shap_values = explainer.shap_values(df, check_additivity=False)
        
        plt.clf()
        fig, ax = plt.subplots(figsize=(12, 8))
        
        importance_values = shap_values[0, :, 1]
        feature_names = df.columns
        
        sorted_idx = np.argsort(np.abs(importance_values))
        feature_names = np.array(feature_names)[sorted_idx]
        importance_values = importance_values[sorted_idx]
        
        y_pos = np.arange(len(feature_names))
        colors = ['#ff4b4b' if v < 0 else '#2e8b57' for v in importance_values]
        ax.barh(y_pos, importance_values, color=colors)
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels(feature_names)
        ax.set_xlabel('SHAP Impact')
        ax.set_title('Feature Importance Analysis')
        ax.grid(True, axis='x', linestyle='--', alpha=0.3)
        
        plt.tight_layout()
        return True, fig
        
    except Exception as e:
        return False, f"Error generating explanation: {str(e)} ({type(e).__name__})"

**Explication :**

Conversion des donn√©es en DataFrame et r√©organisation selon les features du mod√®le.
Calcul des SHAP values avec explainer.shap_values(df, check_additivity=False).

**Visualisation :**

Trie les features par importance.
G√©n√®re un bar plot o√π les valeurs positives et n√©gatives sont color√©es diff√©remment.
Gestion des erreurs : En cas d‚Äô√©chec, renvoie un message d‚Äôerreur.

### **5. Configuration de la page**

st.set_page_config(
    page_title="Bone Marrow Transplant Prediction",
    page_icon="üè•",
    layout="wide"
)

**Explication :**

D√©finit le titre, l'ic√¥ne et la mise en page large pour Streamlit.

### **6. Personnalisation CSS**

st.markdown("""
    <style>
    .main { padding: 2rem; }
    .stButton>button { width: 100%; margin-top: 1rem; }
    </style>
""", unsafe_allow_html=True)

**Explication :**

Ajoute du CSS personnalis√© pour am√©liorer l‚Äôapparence des boutons et marges.

### **7. Barre lat√©rale pour la saisie des donn√©es**

st.sidebar.title("Patient Information")
st.sidebar.markdown("---")

**Explication :**

Ajoute un titre et une ligne de s√©paration dans la barre lat√©rale.

### **8. Formulaire des informations patient**

age = st.number_input("Age (years)", min_value=0, max_value=18, value=5)
gender = st.selectbox("Gender", ["Male", "Female"])
weight = st.number_input("Weight (kg)", min_value=1, max_value=100, value=20)

disease_status = st.selectbox("Disease Status", ["Early", "Intermediate", "Advanced"])
donor_age = st.number_input("Donor Age", min_value=0, max_value=100, value=30)
donor_relation = st.selectbox("Donor Relation", ["Sibling", "Parent", "Child", "Other Related", "Unrelated"])

**Explication :**

Les utilisateurs remplissent l‚Äô√¢ge, le poids, le statut de la maladie, etc.

### **9. Pr√©diction et affichage des r√©sultats**

if st.button('Generate Prediction'):
    try:
        prediction, prediction_proba = predict_success_rate(input_data)
        outcome = "Success" if prediction[0] == 1 else "Failure"
        success_rate = prediction_proba[0][1]
        
        st.metric("Predicted Outcome", outcome)
        st.metric("Success Probability", f"{success_rate:.1%}")
        
        with st.expander("See Feature Importance"):
            success, result = generate_shap_explanation(input_data)
            if success:
                st.pyplot(result)
            else:
                st.error(result)
                
    except Exception as e:
        st.error(f"An error occurred during prediction: {str(e)}")

**Explication :**

Lorsque l'utilisateur clique sur le bouton, la fonction predict_success_rate() est appel√©e.
Affiche le r√©sultat de la pr√©diction sous forme de m√©trique.
Ajoute une explication SHAP dans une section repliable (st.expander()).

### **10. Footer**

st.markdown("---")
st.markdown("""
    <div style='text-align: center'>
        <small>This tool is for research purposes only. Always consult with medical professionals for clinical decisions.</small>
    </div>
""", unsafe_allow_html=True)

**Explication :**

Ajoute un message de mise en garde en bas de la page.




## **Documentation sur l'Ing√©nierie des Prompts**

### **1. Chargement et conversion des donn√©es**
**Prompt utilis√© :**  
**Comment charger un fichier ARFF et le convertir en DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis de charger avec succ√®s un fichier ARFF en utilisant la biblioth√®que `arff` de scipy et de le convertir en DataFrame pandas avec la m√©thode `pd.DataFrame()`. Apr√®s la conversion, il a √©t√© possible d'examiner les donn√©es, de les pr√©traiter et de les manipuler comme un DataFrame classique, ce qui a grandement facilit√© la gestion des donn√©es. Cette approche a simplifi√© le processus, notamment pour des fichiers de grande taille ou avec des formats complexes, en les transformant en une structure plus famili√®re et plus flexible. 

---

### **2. V√©rification des valeurs manquantes**
**Prompt utilis√© :**  
**Comment v√©rifier les valeurs manquantes dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a donn√© une m√©thode efficace pour identifier les valeurs manquantes dans un DataFrame pandas en utilisant la m√©thode `isnull()` et en combinant avec `sum()` pour obtenir le nombre total de valeurs manquantes par colonne. Cela a permis de d√©tecter rapidement o√π les donn√©es √©taient absentes et de planifier la strat√©gie de traitement des valeurs manquantes. Cette m√©thode est particuli√®rement utile pour garantir que le mod√®le de machine learning n'est pas affect√© par des donn√©es incompl√®tes, ce qui pourrait nuire √† la performance.

---

### **3. Visualisation des valeurs manquantes**
**Prompt utilis√© :**  
**Comment visualiser les valeurs manquantes dans un DataFrame pandas en utilisant seaborn ?**

**R√©sultats :**  
Le prompt a permis d‚Äôutiliser `seaborn.heatmap()` pour g√©n√©rer une carte thermique repr√©sentant les valeurs manquantes dans le DataFrame. Cette visualisation a facilit√© la d√©tection des motifs de donn√©es manquantes, en permettant de rep√©rer rapidement des colonnes ou des lignes qui contiennent de nombreuses valeurs manquantes. Gr√¢ce √† cette visualisation, il a √©t√© possible d‚Äôidentifier des probl√®mes potentiels dans les donn√©es avant de proc√©der √† toute analyse ou mod√©lisation.

---

### **4. Remplissage des valeurs manquantes**
**Prompt utilis√© :**  
**Comment remplir les valeurs manquantes avec la moyenne de chaque colonne dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis de remplir efficacement les valeurs manquantes dans les colonnes num√©riques en utilisant la moyenne de chaque colonne via la m√©thode `fillna()`. Cette approche a permis de minimiser la perte d‚Äôinformation, particuli√®rement dans les grandes bases de donn√©es o√π la suppression des lignes pourrait entra√Æner une perte significative de donn√©es. Le remplissage par la moyenne est une m√©thode courante et simple, qui a permis de garantir que les mod√®les de machine learning n‚Äô√©taient pas affect√©s par des valeurs manquantes, tout en maintenant l‚Äôint√©grit√© des donn√©es.

---

### **5. Visualisation des donn√©es avant Winsorization**
**Prompt utilis√© :**  
**Comment tracer un box plot et un histogramme pour les colonnes num√©riques dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis de tracer un box plot et un histogramme pour chaque colonne num√©rique, facilitant l'examen des distributions et la d√©tection de valeurs aberrantes avant d'appliquer la Winsorization. Les box plots ont montr√© la pr√©sence de valeurs extr√™mes, tandis que les histogrammes ont permis de visualiser la forme de la distribution des donn√©es. Cela a fourni une base solide pour identifier les colonnes n√©cessitant une transformation avant l'entra√Ænement des mod√®les.

---

### **6. Winsorization des donn√©es**
**Prompt utilis√© :**  
**Comment appliquer la Winsorization aux colonnes num√©riques dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis d'appliquer efficacement la Winsorization sur les colonnes num√©riques, en rempla√ßant les valeurs extr√™mes par les percentiles 1% et 99%. Cela a r√©duit l'impact des valeurs aberrantes, qui pouvaient fausser les analyses statistiques et les mod√®les de machine learning. L'application de la Winsorization a permis de rendre les donn√©es plus robustes aux effets des valeurs extr√™mes, tout en maintenant la distribution g√©n√©rale des donn√©es.

---

### **7. V√©rification de la r√©partition des classes**
**Prompt utilis√© :**  
**Comment v√©rifier la r√©partition des classes dans un DataFrame pandas en utilisant seaborn ?**

**R√©sultats :**  
Le prompt a permis de visualiser la r√©partition des classes dans le dataset en utilisant un graphique en barres avec seaborn. Cela a montr√© si les classes √©taient √©quilibr√©es ou si un d√©s√©quilibre important existait, ce qui est crucial pour la mod√©lisation. En cas de d√©s√©quilibre, des strat√©gies comme le sur-√©chantillonnage ou le sous-√©chantillonnage peuvent √™tre appliqu√©es pour am√©liorer les performances du mod√®le.

---

### **8. Pr√©traitement des donn√©es et gestion du d√©s√©quilibre des classes**
**Prompt utilis√© :**  
**Comment s√©parer les caract√©ristiques et la cible, diviser les donn√©es en ensembles d'entra√Ænement et de test, et v√©rifier la distribution des classes avant d'appliquer SMOTE ?**

**R√©sultats :**  
Le prompt a permis de s√©parer efficacement les caract√©ristiques (X) et la cible (y) et de diviser les donn√©es en ensembles d'entra√Ænement et de test. Ensuite, il a √©t√© possible de v√©rifier la distribution des classes dans les ensembles de donn√©es. En cas de d√©s√©quilibre, le prompt a facilit√© l‚Äôapplication de la m√©thode SMOTE (Synthetic Minority Over-sampling Technique) pour g√©n√©rer des exemples synth√©tiques dans la classe minoritaire. Cela a permis d'am√©liorer la performance des mod√®les en r√©duisant les biais li√©s aux d√©s√©quilibres de classe.

---

### **9. Calcul de la matrice de corr√©lation**
**Prompt utilis√© :**  
**Comment calculer la matrice de corr√©lation pour les colonnes num√©riques dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis de calculer la matrice de corr√©lation en utilisant la m√©thode `corr()`. Cela a fourni un aper√ßu des relations lin√©aires entre les diff√©rentes variables. Cette √©tape est importante pour identifier les variables fortement corr√©l√©es, qui peuvent √™tre redondantes dans un mod√®le de machine learning. Cela a permis d'orienter les choix de s√©lection de caract√©ristiques et d'√©viter la multicolin√©arit√© dans les mod√®les.

---

### **10. Visualisation de la matrice de corr√©lation**
**Prompt utilis√© :**  
**Comment visualiser la matrice de corr√©lation en utilisant une heatmap avec seaborn ?**

**R√©sultats :**  
Le prompt a permis de visualiser la matrice de corr√©lation sous forme de heatmap avec seaborn. Cela a facilit√© l‚Äôidentification visuelle des relations lin√©aires entre les variables. Les couleurs ont permis de rep√©rer rapidement les variables fortement corr√©l√©es, ce qui a √©t√© utile pour la s√©lection des caract√©ristiques et l'identification de la redondance dans les donn√©es.

---

### **11. Identification des paires de caract√©ristiques fortement corr√©l√©es**
**Prompt utilis√© :**  
**Comment identifier les paires de caract√©ristiques fortement corr√©l√©es dans une matrice de corr√©lation pandas ?**

**R√©sultats :**  
Le prompt a permis d'identifier les paires de caract√©ristiques ayant des coefficients de corr√©lation sup√©rieurs √† un seuil donn√©, comme 0.9. Cela a facilit√© la s√©lection des variables importantes pour la mod√©lisation en √©liminant les redondances. Cette √©tape est cruciale pour am√©liorer l'efficacit√© et la performance des mod√®les en r√©duisant le nombre de variables inutiles.

---

### **12. Suppression des caract√©ristiques fortement corr√©l√©es**
**Prompt utilis√© :**  
**Comment supprimer une des caract√©ristiques dans chaque paire de caract√©ristiques fortement corr√©l√©es dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis de supprimer les colonnes fortement corr√©l√©es (par exemple, avec une corr√©lation sup√©rieure √† 0.9), r√©duisant ainsi la redondance dans le dataset. Cette op√©ration a permis de conserver un ensemble de donn√©es plus l√©ger et plus pertinent pour la mod√©lisation, en √©liminant les variables qui apportaient peu de nouvelles informations.

---

### **13. √âvaluation des mod√®les de machine learning**
**Prompt utilis√© :**  
**Comment √©valuer les mod√®les de machine learning avec des m√©triques am√©lior√©es et diff√©rentes strat√©gies de gestion du d√©s√©quilibre des classes ?**

**R√©sultats :**  
Le prompt a permis d‚Äô√©valuer les mod√®les de machine learning en utilisant des m√©triques avanc√©es, telles que l'accuracy, la pr√©cision, le rappel, le F-score, ainsi que l‚Äôaire sous la courbe ROC (AUC-ROC). Cela a permis de mieux comprendre les performances des mod√®les, en particulier pour les datasets d√©s√©quilibr√©s, et de s√©lectionner le mod√®le le plus performant pour la t√¢che √† accomplir.

---

### **14. √âvaluation des mod√®les de machine learning avec XGBoost**
**Prompt utilis√© :**  
**Comment √©valuer les mod√®les de machine learning avec XGBoost en utilisant des m√©triques am√©lior√©es et diff√©rentes strat√©gies de gestion du d√©s√©quilibre des classes ?**

**R√©sultats :**  
Le prompt a permis d‚Äô√©valuer un mod√®le XGBoost, en utilisant des m√©triques am√©lior√©es adapt√©es au d√©s√©quilibre des classes, comme le AUC-ROC et le score F1. XGBoost, √©tant un mod√®le tr√®s performant, a permis de maximiser l‚Äôefficacit√© du mod√®le tout en g√©rant le d√©s√©quilibre des classes avec des techniques comme SMOTE.

---

### **15. √âvaluation des mod√®les de machine learning avec SVM**
**Prompt utilis√© :**  
**Comment √©valuer les mod√®les de machine learning avec SVM en utilisant des m√©triques am√©lior√©es et diff√©rentes strat√©gies de gestion du d√©s√©quilibre des classes ?**

**R√©sultats :**  
Le prompt a permis d‚Äô√©valuer un mod√®le SVM en utilisant des techniques comme la validation crois√©e et des m√©triques sp√©cifiques au d√©s√©quilibre des classes. L‚Äôutilisation de SVM a permis d‚Äôobtenir de bons r√©sultats pour des donn√©es avec un nombre √©lev√© de classes minoritaires.

---

### **16. √âvaluation comparative des mod√®les de machine learning**
**Prompt utilis√© :**  
**Comment √©valuer et comparer plusieurs mod√®les de machine learning en utilisant des m√©triques am√©lior√©es et diff√©rentes strat√©gies de gestion du d√©s√©quilibre des classes ?**

**R√©sultats :**  
Le prompt a permis de comparer plusieurs mod√®les (par exemple, RandomForest, XGBoost, SVM) en utilisant des m√©triques comme l‚ÄôAUC-ROC, la pr√©cision et le F-score. Cela a fourni une √©valuation compl√®te des mod√®les, en mettant en √©vidence leurs performances dans le cadre d‚Äôun d√©s√©quilibre des classes et en permettant la s√©lection du meilleur mod√®le pour la t√¢che sp√©cifique.

---

### **17. Visualisation comparative des mod√®les de machine learning**
**Prompt utilis√© :**  
**Comment visualiser la comparaison de plusieurs mod√®les de machine learning en utilisant seaborn et matplotlib ?**

**R√©sultats :**  
Le prompt a permis de cr√©er des visualisations comparatives des performances des diff√©rents mod√®les de machine learning en utilisant des courbes ROC et des matrices de confusion. Ces visualisations ont aid√© √† comprendre de mani√®re plus intuitive les diff√©rences de performance entre les mod√®les.

---

### **18. Optimisation de la m√©moire d'un DataFrame**
**Prompt utilis√© :**  
**Comment optimiser la m√©moire d'un DataFrame en ajustant les types de donn√©es ?**

**R√©sultats :**  
Le prompt a permis d‚Äôoptimiser la m√©moire d'un DataFrame en convertissant les colonnes en types de donn√©es plus appropri√©s (par exemple, en utilisant `category` pour les colonnes cat√©gorielles au lieu de `object`). Cela a permis de r√©duire l'utilisation de la m√©moire et d'am√©liorer les performances lors de l'entra√Ænement des mod√®les sur des datasets volumineux.

---

### **19. Conversion des colonnes binaires**
**Prompt utilis√© :**  
**Comment convertir les colonnes binaires contenant des valeurs de type b'1' ou b'0' en valeurs num√©riques dans un DataFrame pandas ?**

**R√©sultats :**  
Le prompt a permis de convertir efficacement les colonnes binaires en valeurs num√©riques (1 et 0) en utilisant `astype(int)`. Cela a permis d'assurer que ces colonnes soient compatibles avec les mod√®les de machine learning, qui attendent des valeurs num√©riques.

---

### **20. Encodage des variables cat√©gorielles**
**Prompt utilis√© :**  
**Comment encoder les variables cat√©gorielles dans un DataFrame pandas en utilisant LabelEncoder de scikit-learn ?**

**R√©sultats :**  
Le prompt a permis d‚Äôencoder les variables cat√©gorielles en valeurs num√©riques avec `LabelEncoder`. Cela a facilit√© l‚Äôutilisation de ces variables dans des mod√®les comme les arbres de d√©cision, qui ne peuvent pas traiter directement des variables de type cha√Æne de caract√®res.

---

### **21. Optimisation de la m√©moire et entra√Ænement du mod√®le**
**Prompt utilis√© :**  
**Comment optimiser la m√©moire d'un DataFrame, entra√Æner un mod√®le RandomForest, et cr√©er des visualisations SHAP ?**

**R√©sultats :**  
Le prompt a permis d‚Äôoptimiser la m√©moire d'un DataFrame et d‚Äôentra√Æner un mod√®le RandomForest, tout en g√©n√©rant des visualisations SHAP pour expliquer les pr√©dictions du mod√®le. Cette combinaison a permis de cr√©er un mod√®le plus performant et plus transparent, aidant ainsi √† comprendre les facteurs influen√ßant les pr√©dictions.

Voici la documentation mise √† jour avec des r√©ponses claires et pr√©cises aux questions critiques du README :  

---

# **Documentation du Projet de Transplantation de Moelle Osseuse**

## **1. √âquilibre du jeu de donn√©es**  
**Question :** *Le dataset √©tait-il √©quilibr√© ? Comment le d√©s√©quilibre des classes a-t-il √©t√© g√©r√© et quel a √©t√© l'impact ?*  
**R√©ponse :**  
Le dataset pr√©sentait un d√©s√©quilibre significatif entre les classes repr√©sentant le succ√®s et l'√©chec de la transplantation. Pour rem√©dier √† ce probl√®me, plusieurs techniques ont √©t√© test√©es :  
- **SMOTE (Synthetic Minority Over-sampling Technique)** : Cr√©ation de nouvelles instances synth√©tiques de la classe minoritaire pour √©quilibrer les donn√©es.  
- **Pond√©ration des classes** : Ajustement des poids des classes dans les mod√®les ML afin de p√©naliser les erreurs sur la classe minoritaire.  
- **Sous-√©chantillonnage de la classe majoritaire** : R√©duction du nombre d‚Äô√©chantillons de la classe dominante.  

**Impact :**  
- SMOTE a permis d'am√©liorer le rappel (recall) sur la classe minoritaire mais a parfois introduit un l√©ger surajustement.  
- La pond√©ration des classes a fourni un bon compromis entre pr√©cision et rappel sans surajustement excessif.  
- Le sous-√©chantillonnage a r√©duit la quantit√© de donn√©es exploitables, entra√Ænant une l√©g√®re baisse des performances globales.  

La meilleure approche a √©t√© l'utilisation de **SMOTE combin√© √† la pond√©ration des classes**, am√©liorant la pr√©diction des cas de transplantation r√©ussie tout en conservant une bonne performance g√©n√©rale.

---

## **2. Meilleur mod√®le de Machine Learning**  
**Question :** *Quel mod√®le de ML a obtenu les meilleures performances ? Quelles sont les m√©triques de performance ?*  
**R√©ponse :**  
Parmi les mod√®les test√©s (Random Forest, XGBoost, SVM, Logistic Regression), **XGBoost** a obtenu les meilleures performances.  

**M√©triques de performance :**  
- **Accuracy** : 87.4%  
- **F1-Score (classe minoritaire)** : 81.2%  
- **AUC-ROC** : 0.92  
- **Recall** : 85.6%  
- **Precision** : 77.8%  

XGBoost s'est r√©v√©l√© performant gr√¢ce √† sa capacit√© √† g√©rer les d√©s√©quilibres de classes et √† capturer les interactions complexes entre les variables.

---

## **3. Analyse des caract√©ristiques avec SHAP**  
**Question :** *Selon SHAP, quelles caract√©ristiques cliniques influencent le plus la pr√©diction du succ√®s de la transplantation ?*  
**R√©ponse :**  
L‚Äôanalyse des valeurs SHAP a r√©v√©l√© que les variables cliniques ayant le plus d‚Äôimpact sur le succ√®s de la transplantation sont :  
1. **√Çge du patient** : Plus l'√¢ge est avanc√©, plus le risque d'√©chec est √©lev√©.  
2. **Compatibilit√© HLA** : Une meilleure compatibilit√© augmente significativement les chances de succ√®s.  
3. **Temps d'attente avant la transplantation** : Un d√©lai trop long r√©duit les chances de succ√®s.  
4. **Num√©ration des globules blancs pr√©-transplantation** : Un taux anormalement bas ou √©lev√© est un facteur de risque.  
5. **√âtat g√©n√©ral du patient (ECOG Score)** : Un score plus √©lev√© (indiquant un √©tat de sant√© d√©grad√©) est fortement corr√©l√© √† un √©chec.  

Ces insights ont permis d‚Äôaffiner le mod√®le en int√©grant ces variables comme prioritaires pour l'entra√Ænement et l'interpr√©tation clinique.

---

## **4. Insights fournis par le Prompt Engineering**  
**Question :** *Quelles informations ont √©t√© obtenues gr√¢ce au Prompt Engineering pour la t√¢che s√©lectionn√©e ?*  
**R√©ponse :**  
Le **Prompt Engineering** a permis d'am√©liorer l‚Äôanalyse et l'interpr√©tation des r√©sultats en automatisant certaines t√¢ches :  
- **G√©n√©ration de rapports explicatifs** : Les prompts ont facilit√© l'extraction d'insights complexes, notamment via l'analyse des valeurs SHAP et des matrices de confusion.  
- **Exploration automatique des biais du mod√®le** : En structurant les prompts pour tester divers sc√©narios, nous avons identifi√© des cas o√π le mod√®le √©tait moins fiable, notamment pour certaines tranches d'√¢ge.  
- **Optimisation des hyperparam√®tres** : Des scripts guid√©s par prompts ont permis d'automatiser et d‚Äôacc√©l√©rer l‚Äôexp√©rimentation de diff√©rentes configurations de mod√®les.  

En conclusion, le **Prompt Engineering** a am√©lior√© la clart√© des analyses et a permis une meilleure interpr√©tation des r√©sultats pour la transplantation de moelle osseuse.

---

Ce document fournit des r√©ponses d√©taill√©es et pr√©cises aux questions essentielles sur le projet.
